# Session Handoff — 1 January 2025

**Project:** ExamRizz Arena
**Session Focus:** Matching algorithm audit → Full assessment redesign
**Duration:** Extended session
**Status:** Major design iteration complete, ready for implementation

---

## Quick Context (Read First)

ExamRizz Arena is a UK university course matching platform for sixth-form students. It uses psychometric assessment to match students to degree programs based on cognitive capacity, learning dispositions, and preferences — not just grades.

**Philosophy:** "Elite pushing" — recommend the best universities students can realistically attend. Russell Group is default. Brutal honesty about fit, but prescriptive not dismissive.

**This session:** Started debugging why matches felt "random". Discovered fundamental gaps. Ended up redesigning the entire assessment model.

---

## What Happened This Session

### 1. Algorithm Audit
Traced the matching pipeline from scoring.ts → matching.ts. Found:

| Issue | Severity | Status |
|-------|----------|--------|
| Capacity layer calculated but never used | High | Design fixed, code pending |
| subject_tags empty (0/28,520 courses) | High | Known, low priority (vibe is tiebreaker) |
| Penalty symmetry wrong (excess penalised same as deficit) | High | Design fixed, code pending |
| Russell Group bonus too weak (+5) | Medium | Design fixed (+15 and two-tier results) |
| Grade filter missing | Critical | Design spec'd, code pending |
| HESA fields mostly null | Medium | Accepted limitation |

### 2. Matching Model Redesign
New 5-layer hierarchy:

```
1. GRADES        → Hard gate (only hard filter)
2. CAPACITY      → Soft gate (benchmark performance)
3. ENJOYMENT     → Core ranking (post-task ratings)
4. DISPOSITION   → Refinement (forced-choice scenarios)
5. PREFERENCE    → Tiebreaker (vibe + quality)
```

### 3. No-Likert Decision
Eliminated all Likert-scale questions. Replaced with:
- Benchmark performance (objective ability)
- Enjoyment ratings (behavioural preference)
- Forced-choice scenarios (trade-off preferences)
- Behavioural proxies (response patterns)

### 4. Floor vs Fit Logic
Fixed penalty symmetry. Dispositions now categorised:

| Type | Behaviour | Dimensions |
|------|-----------|------------|
| FLOOR | Only deficit penalised | Calibration, Tolerance, Precision, Retrieval |
| FIT | Both directions penalised | Transfer, Receptivity, Structure, Consistency, Social, Depth |

### 5. Forced-Choice Question Bank
Designed 25 items:
- 4 items × 5 primary constructs (Social, Receptivity, Transfer, Structure, Depth)
- 1 item × 5 backup constructs (Calibration, Tolerance, Precision, Retrieval, Consistency)
- 15-18 served per session (randomised)
- 8-10 second time limit per item
- Optional comment field for AI analysis

### 6. Two-Tier Results
Results now show two lists:
- **Top Matches:** Best-fit Russell Group courses
- **Best Fit For You:** Highest fit regardless of prestige

### 7. Enjoyment Dimensions
Foundation defined for benchmark design:

| Dimension | Maps To |
|-----------|---------|
| Verbal | Essay-heavy, reading-intensive |
| Quantitative | Maths, data, economics |
| Time Pressure | Exam-heavy assessment |
| Abstract/Pattern | Pure sciences, theory, research |
| Applied/Contextual | Professional, vocational |
| Open-Ended | Creative, research degrees |

---

## Documents Created This Session

| File | Purpose | Location |
|------|---------|----------|
| MATCHING_MODEL.md | Canonical matching algorithm spec | /home/claude/ → download |
| FORCED_CHOICE_BANK.md | All 25 forced-choice items with mappings | /home/claude/ → download |
| STUDENT_SIMULATION_PROMPT.md | Meta-prompt for UX testing via personas | /home/claude/ → download |

**Add these to your repo in `/docs/`**

---

## Key Decisions Made

| Decision | Rationale | Reversible? |
|----------|-----------|-------------|
| No Likert scales | Higher validity, harder to fake, better UX | Yes, but shouldn't |
| Grades as only hard filter | Everything else is fit, not eligibility | No — core philosophy |
| Capacity as soft gate, not filter | Don't close doors, be prescriptive | Yes |
| Enjoyment above disposition in hierarchy | Behavioural > attitudinal, research-backed | Yes |
| 8-10 sec timing on forced-choice | Anti-gaming mechanism | Yes |
| Background timing on benchmarks | Capture data without anxiety (first run) | Yes |
| Two-tier results (Elite + Best Fit) | Maintain elite push while showing pure fit | No — good design |
| Optional comments on all items | AI extracts nuance, conflict, gaming signals | Yes |
| 25 forced-choice items, 15-18 per session | α ~0.80 reliability, fresh retakes | Tune based on data |

---

## Open Questions (Not Yet Resolved)

| Question | Options | Recommendation |
|----------|---------|----------------|
| CON_01 too transparent? | Rework vs keep | Monitor gaming, rework if needed |
| Abstract/Pattern benchmark items | Use existing 72 vs design fresh | Phase 2: Review existing first |
| Capacity floors for courses | Derive from CAH vs entry tariffs vs manual | Derive from entry tariffs initially |
| Enjoyment → course mapping weights | Define now vs tune empirically | Tune empirically after data |

---

## What's Built vs What's Designed

| Component | Status |
|-----------|--------|
| Assessment flow (vibe → questions → results) | Built, deployed |
| Scoring logic (scoring.ts) | Built, needs update |
| Matching logic (matching.ts) | Built, needs significant update |
| Forced-choice questions | Designed, not built |
| Enjoyment ratings | Designed, not built |
| Grade input | Designed, not built |
| Capacity benchmarks | 72 items in DB, no UI |
| Two-tier results | Designed, not built |
| Behavioural proxy tracking | Not designed |

---

## Next Steps (Prioritised)

### Immediate (Before Coding)
1. ✅ Download and add docs to repo
2. Review FORCED_CHOICE_BANK.md for any wording tweaks
3. Decide on CON_01 — keep or rework

### Phase 2: Benchmark Item Review
1. Pull existing 72 items from DB
2. Tag for enjoyment dimension
3. Flag weak/ambiguous items
4. Identify gaps (Abstract/Pattern, Applied/Contextual sections)

### Phase 3: Implementation
1. Update scoring.ts with new construct sources
2. Update matching.ts with Floor vs Fit logic
3. Build forced-choice UI
4. Build enjoyment rating UI
5. Build grade input
6. Build two-tier results display

### Phase 4: Data
1. Populate capacity_vrb_floor etc. for courses (derive from entry tariffs)
2. Optionally backfill subject_tags from CAH codes

---

## Key Files in Project

| File | Purpose |
|------|---------|
| `/mnt/project/001_schema.sql` | Database schema |
| `/mnt/project/002_questions.sql` | Existing question bank |
| scoring.ts (in repo) | Disposition scoring logic |
| matching.ts (in repo) | Course matching algorithm |
| MATCHING_MODEL.md (new) | Algorithm specification |
| FORCED_CHOICE_BANK.md (new) | Question bank |
| STUDENT_SIMULATION_PROMPT.md (new) | UX testing tool |

---

## User Preferences (For Future Sessions)

- British English
- Brief explanations, no fluff
- Outline plans before implementation
- Single best option, not multiple alternatives
- Don't code without checking first
- Give genuine take, disagree if warranted
- Remind when new context window recommended

---

## Technical Stack

- Next.js 14 + TypeScript
- Supabase (bo_v1_* tables)
- Tailwind + Arcane design system
- Vercel deployment
- Repo: https://github.com/sjsenglish/bo_v1_profile

---

## Session Statistics

- Course data: 28,520 active courses
- Russell Group courses: subset (flagged)
- Disposition demands: CAH-level (10-13 unique values per dimension)
- HESA fields populated: continuation_rate (27,447), employment_rate (24,657)
- HESA fields empty: exam%, practical%, hours, NSS, salary, subject_tags

---

## How to Continue

### Option A: Same Project, New Chat
Start with:
> "Continuing ExamRizz Arena. Last session: completed matching model redesign and forced-choice question bank. Ready for Phase 2: benchmark item review. HANDOFF doc is in project files."

### Option B: Upload Context
Upload these files at start of new chat:
1. This HANDOFF.md
2. MATCHING_MODEL.md
3. FORCED_CHOICE_BANK.md
4. scoring.ts and matching.ts from repo

### Option C: Full Cold Start
If starting completely fresh, upload:
1. This HANDOFF.md (most critical)
2. MASTER_SPEC.md from project
3. DATA_DICTIONARY.md from project

---

## Summary in One Paragraph

ExamRizz Arena matching was audited and found to have capacity layer unused, penalty symmetry wrong, grade filter missing, and vibe data empty. Redesigned to 5-layer model: Grades (hard gate) → Capacity (soft gate) → Enjoyment (core ranking) → Disposition (refinement) → Preference (tiebreaker). Eliminated Likert in favour of benchmarks, enjoyment ratings, and forced-choice scenarios. Created 25 forced-choice items across 10 dispositions with anti-gaming measures (8-10s timing, optional comments for AI analysis). Added two-tier results (Elite + Best Fit) to maintain elite-pushing while showing pure fit alternatives. Floor vs Fit logic fixes penalty symmetry so excess ability isn't penalised. Next: Phase 2 benchmark item review, then implementation.

---

*Generated: End of session, 1 January 2025*
